{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Text Tokenizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We create a specialized text tokenizer that efficiently:\n",
    "- Remove repeated words: what the the the f***?\n",
    "- Trip out the accents:  Le jeu du garçon!?!?!?!?!?!?!?!?!?!? Voilà!!!!\n",
    "- Recognize date, hashtag, emoticons, ect. and split it out.\n",
    "- Replace elongated characters to 3 repeated characters: sooooooooo coooolllllllllllll\n",
    "In order to use it, just import the Tokenzier package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what the the the f**k?\n",
      "---> what the f**k?\n",
      "Le jeu du garçon!?!?!?!?!?!?!?!?!?!? Voilà!!!!\n",
      "---> Le jeu du garcon !?!?!? Voila !!!\n",
      "sooooooooo coooolllllllllllll\n",
      "---> sooo cooolll\n",
      "@cf7@m10 did reallyyyyyyy weeeeelllllll!!!!! #football#fan#inlove ('_')(/_;)(T_T) (;_;)(;_;(;_:)(;O;)(:_;) ;_;;-;;n;;;Q.QT.TTnTQQQ_Q ☹️🙁😠😡😞\n",
      "---> @cf7 @m10 did reallyyy weeelll !!! #football #fan #inlove ('_') (/_;) (T_T) (;_;) (;_; (;_:) (;O;) (:_;) ;_; ;-; ;n; ;; Q.Q T.T TnT QQ Q_Q ☹ 🙁 😠 😡 😞\n",
      "A.A.A..A.S.SS.S.S.SSS.S.S.S.SCCCC.C....RRAAC.C.XK\n",
      "---> A.A.A ... A . S . SS . S . S . SSS . S . S . SCCC . C ... RRAAC .C.XK\n",
      "Hold brb im writing this sht in my own WORDSSSS ;-;\n",
      "---> Hold brb im writing this sht in my own WORDSSS ;-;\n",
      "teammmmmm come oooonn\n",
      "---> teammm come ooonn\n",
      "YELLOW YELLOW YELLOW YELLOW YELLOW YELLOW YELLOW YELLOW????????????????????Galaxy Adidas Shoes??FAV=CHEAP\n",
      "---> YELLOW ? ? ? Galaxy Adidas Shoes ? ? FAV = CHEAP\n",
      "afgffffffffffffffffffffffffffggggggggggggggggggggggiiyyyyyuuuuuuvvvvvvvvmmmmmmmmmmmmmmmmm ymmmmmmmmmmiiiiiiiiiiiiiii bbbbbv mnbvyngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngmvuivimikmikmikmikmikmikmikmvfytterxstrx B BUUUUUCKERS\n",
      "---> afgfffgggiiyyyuuuvvvmmm ymmmiii bbbv mnbvyngngngmvuivimikmikmikmvfytterxstrx B BUUUCKERS\n",
      "HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY\n",
      "---> HOLY SHT HOLY\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from utils.preprocess import Tokenizer\n",
    "splitter = Tokenizer()\n",
    "examples=[\"what the the the f**k?\",\n",
    "          \"Le jeu du garçon!?!?!?!?!?!?!?!?!?!? Voilà!!!!\",\n",
    "          \"sooooooooo coooolllllllllllll\",\n",
    "          \"@cf7@m10 did reallyyyyyyy weeeeelllllll!!!!! #football#fan#inlove ('_')(/_;)(T_T) (;_;)(;_;(;_:)(;O;)(:_;) ;_;;-;;n;;;Q.QT.TTnTQQQ_Q ☹️🙁😠😡😞\",\n",
    "         \"A.A.A..A.S.SS.S.S.SSS.S.S.S.SCCCC.C....RRAAC.C.XK\",\n",
    "         \"Hold brb im writing this sht in my own WORDSSSS ;-;\",\n",
    "         \"teammmmmm come oooonn\",\n",
    "         \"YELLOW YELLOW YELLOW YELLOW YELLOW YELLOW YELLOW YELLOW????????????????????Galaxy Adidas Shoes??FAV=CHEAP\",\n",
    "         \"afgffffffffffffffffffffffffffggggggggggggggggggggggiiyyyyyuuuuuuvvvvvvvvmmmmmmmmmmmmmmmmm ymmmmmmmmmmiiiiiiiiiiiiiii bbbbbv mnbvyngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngngmvuivimikmikmikmikmikmikmikmvfytterxstrx B BUUUUUCKERS\",\n",
    "         \"HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY SHT HOLY\"]\n",
    "\n",
    "for line in examples:\n",
    "    print(line)\n",
    "    print(\"---> \"+' '.join(splitter.tokenize(line)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The list of emoticons and url domain could be augmented in the file /lexicons/emoticons.txt and /lexicons/domains.txt, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusable Replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic code is followed by:\n",
    "- First, we tokenize a line into single words\n",
    "- Then, we check if it is dangeous or not by using the blocks.txt file at http://www.unicode.org/\n",
    "- Finally, replace all confusable characters in a dangeous word based on confusable.txt file at http://www.unicode.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Blocks.txt data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000..007F</th>\n",
       "      <th>Basic Latin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0080..00FF</td>\n",
       "      <td>Latin-1 Supplement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100..017F</td>\n",
       "      <td>Latin Extended-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0180..024F</td>\n",
       "      <td>Latin Extended-B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0250..02AF</td>\n",
       "      <td>IPA Extensions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02B0..02FF</td>\n",
       "      <td>Spacing Modifier Letters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0300..036F</td>\n",
       "      <td>Combining Diacritical Marks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0370..03FF</td>\n",
       "      <td>Greek and Coptic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0400..04FF</td>\n",
       "      <td>Cyrillic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0500..052F</td>\n",
       "      <td>Cyrillic Supplement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0530..058F</td>\n",
       "      <td>Armenian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0000..007F                   Basic Latin\n",
       "0  0080..00FF            Latin-1 Supplement\n",
       "1  0100..017F              Latin Extended-A\n",
       "2  0180..024F              Latin Extended-B\n",
       "3  0250..02AF                IPA Extensions\n",
       "4  02B0..02FF      Spacing Modifier Letters\n",
       "5  0300..036F   Combining Diacritical Marks\n",
       "6  0370..03FF              Greek and Coptic\n",
       "7  0400..04FF                      Cyrillic\n",
       "8  0500..052F           Cyrillic Supplement\n",
       "9  0530..058F                      Armenian"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "blocks = pd.read_csv('./utils/lexicons/UNIDATA_Blocks.txt', delimiter=\";\", comment=\"#\")\n",
    "print(\"Examples of Blocks.txt data\")\n",
    "blocks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of confusable.txt data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05AD</th>\n",
       "      <th>0596</th>\n",
       "      <th>MA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>F9C4</td>\n",
       "      <td>\\t9F8D</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>2FD3</td>\n",
       "      <td>\\t9F8D</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>FAD9</td>\n",
       "      <td>\\t9F8E</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>2EF0</td>\n",
       "      <td>\\t9F99</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>F907</td>\n",
       "      <td>\\t9F9C</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>F908</td>\n",
       "      <td>\\t9F9C</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>FACE</td>\n",
       "      <td>\\t9F9C</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>2FD4</td>\n",
       "      <td>\\t9F9C</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>2EF3</td>\n",
       "      <td>\\t9F9F</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>2FD5</td>\n",
       "      <td>\\t9FA0</td>\n",
       "      <td>\\tMA\\t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      05AD   \\t0596   \\tMA\\t\n",
       "6283  F9C4   \\t9F8D   \\tMA\\t\n",
       "6284  2FD3   \\t9F8D   \\tMA\\t\n",
       "6285  FAD9   \\t9F8E   \\tMA\\t\n",
       "6286  2EF0   \\t9F99   \\tMA\\t\n",
       "6287  F907   \\t9F9C   \\tMA\\t\n",
       "6288  F908   \\t9F9C   \\tMA\\t\n",
       "6289  FACE   \\t9F9C   \\tMA\\t\n",
       "6290  2FD4   \\t9F9C   \\tMA\\t\n",
       "6291  2EF3   \\t9F9F   \\tMA\\t\n",
       "6292  2FD5   \\t9FA0   \\tMA\\t"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusable = pd.read_csv('./utils/lexicons/UNIDATA_confusables.txt', delimiter=\";\", comment=\"#\")\n",
    "print(\"Examples of confusable.txt data\")\n",
    "confusable.tail(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is easy to add more rules into confusable.txt file to handle specific mixing. To replace confusable characters for a sentence, we add a simplify function to in-turn process the algorithm above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.other_utils import Encoder, Csvfile\n",
    "from utils.confusables import is_dangeous, alter_word\n",
    "def simplify(text):\n",
    "    line = Encoder.str2uni(text)\n",
    "    sent = splitter.tokenize(line)\n",
    "    sent = [alter_word(word) if is_dangeous(word) else word for word in sent]\n",
    "    newline = Encoder.uni2str(u' '.join(sent))\n",
    "    return newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℬ B\n",
      "ρ p\n",
      "æ ae\n",
      "ꜹ av\n",
      "𝕔 c\n",
      "𝒻 f\n",
      "Bitch paech Jav cunt fuck\n"
     ]
    }
   ],
   "source": [
    "print(simplify(\"ℬitch ρæch Jꜹ 𝕔unt 𝒻uck\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put All Together"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We build a pre_process function to read line-by-line the input file. Then, we simplify it and write it into a new output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(inpfile,outfile):\n",
    "    inpdata=Csvfile(inpfile,textpos=None,firstline=True, split=True)\n",
    "    splitter = Tokenizer()\n",
    "    \n",
    "    data = []\n",
    "    for line in inpdata:\n",
    "        text, label, idx = line\n",
    "        line = Encoder.str2uni(text)\n",
    "        sent = splitter.tokenize(line)\n",
    "        sent = [alter_word(word) if is_dangeous(word) else word for word in sent]\n",
    "        newline = Encoder.uni2str(u' '.join(sent))\n",
    "        data.append([newline, label, idx])\n",
    "    \n",
    "    header = inpdata.firstline\n",
    "    data = [header] + data\n",
    "    Writefile.csvfile(data,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    python process_line.py --inpfile <input-filename> --outfile <output_filename> \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
